{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b336afda-1d4f-48e8-a1c0-9ee383b251cf",
   "metadata": {},
   "source": [
    "##### üèóÔ∏è Activity #1:\n",
    "\n",
    "Please evaluate your system on the following questions:\n",
    "\n",
    "1. Explain the concept of object-oriented programming in simple terms to a complete beginner. \n",
    "    - Aspect Tested:\n",
    "2. Read the following paragraph and provide a concise summary of the key points‚Ä¶\n",
    "    - Aspect Tested:\n",
    "3. Write a short, imaginative story (100‚Äì150 words) about a robot finding friendship in an unexpected place.\n",
    "    - Aspect Tested:\n",
    "4. If a store sells apples in packs of 4 and oranges in packs of 3, how many packs of each do I need to buy to get exactly 12 apples and 9 oranges?\n",
    "    - Aspect Tested:\n",
    "5. Rewrite the following paragraph in a professional, formal tone‚Ä¶\n",
    "    - Aspect Tested:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412a2ad4-c102-42e3-8fbd-1ba5a51577d6",
   "metadata": {},
   "source": [
    "**Let's evaluate the simple chainlit application (which interfaces with gpt-3.5-turbo) on each of these.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3384d510-26e4-4afa-b8d3-219d42fe4ea8",
   "metadata": {},
   "source": [
    "##### Question01\n",
    "**Explain the concept of object-oriented programming in simple terms to a complete beginner.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5911a7b8-0b89-4e55-b74c-bb3a519f1eb6",
   "metadata": {},
   "source": [
    "![question01](question01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa48b56a-ff58-4a44-9395-d07f0983656a",
   "metadata": {},
   "source": [
    "**Aspect Tested**\n",
    "1. This question tests the general ability of the LLM to be a helpful assistant and provide reasonable answers.\n",
    "2. It also tests its expert knowledge (the question is very domain-specific to programming)\n",
    "3. Finally, it can be used to test thoroughness if the goal is to evaluate salient aspects of the answer.\n",
    "\n",
    "Overall, the LLM did a decent job in summarizing the key aspects of Object Oriented Programming. I didn't ask any specific details so this summary is reasonable at a high level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067c8ab-6e1d-4f26-bdfe-d2411c46a112",
   "metadata": {},
   "source": [
    "##### Question02\n",
    "**Read the following paragraph and provide a concise summary of the key points**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d0f2f5-b865-4247-abe0-788280dde93e",
   "metadata": {},
   "source": [
    "![question02](question02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1050-361d-425e-8984-2a930cbafaf4",
   "metadata": {},
   "source": [
    "**Aspect Tested**\n",
    "1. The ability of the LLM to read and comprehend short paragraphs\n",
    "2. The ability of the LLM to summarize the salient aspects of the paragraph\n",
    "3. The ability of the LLM to paraphrase facts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdcf8b1-a717-47e7-a957-3a4da183fd37",
   "metadata": {},
   "source": [
    "Overall, this summary is reasonable. However, I did note that the summary didn't specify that it is implied that Miguel Ojeda is both a Google employee and a Linux kernel developer. It also didn't mention that the use of Rust makes addressing memory bugs *cost* effective. But overall this is a reasonable answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd564c76-9274-424a-a108-596eb83d1819",
   "metadata": {},
   "source": [
    "##### Question03\n",
    "Write a short, imaginative story (100‚Äì150 words) about a robot finding friendship in an unexpected place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b82b6-d90b-43fc-9527-9dd8f6a40610",
   "metadata": {},
   "source": [
    "![question03](question03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f5c7f-ad2d-4748-b2d1-337f7fffa06e",
   "metadata": {},
   "source": [
    "Aspect Tested:\n",
    "1. Creativity in crafting a narrative and story-telling.\n",
    "2. Ability to come up with coherent facts which are consistent with the rest of the narrative.\n",
    "3. General comprehension of the user's request.\n",
    "\n",
    "Overall, in this case, the LLM did a better job coming up with a story on short-notice than I would have. One small thing I noticed was that it didn't pay much attention to the \"unexpected\" part of the request. However, I guess the line \"Spark spent his days wandering the city disconnected from the world around him\" puts some emphasis on this (given that he finds the squirrel in a forgotten garden)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d91769f-2e2d-46b2-a91b-bcd14180027b",
   "metadata": {},
   "source": [
    "##### Question04\n",
    "If a store sells apples in packs of 4 and oranges in packs of 3, how many packs of each do I need to buy to get exactly 12 apples and 9 oranges?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88803c-9a92-468e-9529-5513aea99cdb",
   "metadata": {},
   "source": [
    "![question04](question04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a55b3e4-3b6a-49f9-a010-04967939126b",
   "metadata": {},
   "source": [
    "Aspect Tested:\n",
    "1. Ability to comprehend *simple* mathematical problems.\n",
    "2. Ability to reason through the mathematical problem\n",
    "3. Ability to answer simple mathematical problems correctly.\n",
    "\n",
    "I was surprised but gpt-3.5-turbo actually does a good job on this problem. Not only does it come up with a correct answer, but it also reasons through it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4305b836-80dc-4fdb-b593-f4a16b838713",
   "metadata": {},
   "source": [
    "##### Question05\n",
    "Rewrite the following paragraph in a professional, formal tone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecb6b4b-8662-484e-8461-861bfb6575a4",
   "metadata": {},
   "source": [
    "![question05](question05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c179be-41d9-469d-8bc8-96a042832964",
   "metadata": {},
   "source": [
    "Aspect Tested:\n",
    "1. Reading comprehension and understanding of the provided paragraph.\n",
    "2. Ability to generally understand \"professional, formal tone\".\n",
    "3. Ability to rewrite the paragraph while retaining the salient details.\n",
    "\n",
    "Once again, in this case, the LLM does a decent job at this problem. I did notice it used words like \"poignant\" and \"imperative\" which might not have been required but I guess formality lies in the eyes of the beholder in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd1b3ac-8a37-4752-8e38-f96f353a1bfb",
   "metadata": {},
   "source": [
    "### Testing Changes to the Deployment\n",
    "Now we test the same questions after making a few changes to the sampling hyperparameters based on this [article](https://community.openai.com/t/cheat-sheet-mastering-temperature-and-top-p-in-chatgpt-api/172683). In particular, I tweaked the temperature and top_p parameters to focus on a combination of creativity and reasoning (leading to slightly more verbose answers below). I also changed the base llm to `gpt-4o`.\n",
    "\n",
    "A screenshot of the answers for the same questions using new parameters is attached below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac870d7c-82ed-4630-a4d3-be8269d7bf12",
   "metadata": {},
   "source": [
    "##### Question01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953f90ba-4369-4a54-a502-a3aff2ecaef8",
   "metadata": {},
   "source": [
    "![question01 with new parameters](question07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b8ab02-76e9-43fe-83e2-0f8a5b223c3a",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "We notice that this time round, the LLM makes fewer assumptions about prior knowledge and provides some relevant background for the layman.The answer is also longer, more thorough and has more examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ea0f3-1f3e-476d-a680-06b7ffb992de",
   "metadata": {},
   "source": [
    "##### Question02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f79a81-7245-40e2-a47e-6ecaba60ec03",
   "metadata": {},
   "source": [
    "![question02 with new parameters](question08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec80d5f1-0bd5-4867-8014-9e2a6f7d4b95",
   "metadata": {},
   "source": [
    "##### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e93a9df-abeb-40b3-9809-00d8018fda1c",
   "metadata": {},
   "source": [
    "Few things to note here. Since we requested \"key points\", the LLM has answered with a reasoned summary of the key points in a numbered list. Thereafter it provides a summary paragraph. This time **it does capture the cost-effective nature of Rust** but still doesn't catch the implied point that Miguel Ojeda is a Google Employee.\n",
    "\n",
    "Another thing to note here is that the LLM focused on verbosity. This would be bad if we were using it and expecting a short answer as opposed to a reasoned summary. In many ways, the answer is longer than the paragraph, but the summary itself is short. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3917f0c-712b-423b-b96e-0acf2b574ffe",
   "metadata": {},
   "source": [
    "##### Question03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6864825-5100-41f5-bddc-605a3f7e9147",
   "metadata": {},
   "source": [
    "![question03 with new parameters](question09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b1dc5-187a-40de-a062-99b39901ee0a",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "This time round, the LLM describes the setting (\"bustling city where humans and robots coexist\") and describes the cast of charactersa and outline before tellingv the story. The LLM also focuses on aspects like \"surprised\" to tie back to the \"unexpected\" part of the user's request."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c5b86-6dcf-46b8-b439-6bc949f71fa5",
   "metadata": {},
   "source": [
    "##### Question04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9f563-3797-4460-b218-797f622214ad",
   "metadata": {},
   "source": [
    "![question04 with new parameters](question10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c4e667-94ba-4b59-b3b4-f2fa0d335524",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "Once again, the LLM reasoned through the answer and came up with the correct answer. However, the answer and reasoning was more verbose (since we tweaked the creativity parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a72cee0-5764-481e-829c-e5e1189dfa35",
   "metadata": {},
   "source": [
    "##### Question05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a39a33-1cca-4174-8318-eaf93c8e2d00",
   "metadata": {},
   "source": [
    "![question05 with new parameters](question11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b45e363-3617-4741-8977-8dec012ada49",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "Not too many changes to the answer on this front, except slightly different language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62a8193-6c0f-4e0d-86af-295419e091f2",
   "metadata": {},
   "source": [
    "#### Limitations of Vibe Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839bac4-0f9e-41e1-9bd7-8317864b0d9a",
   "metadata": {},
   "source": [
    "Vibe check isn't an exhaustive tool. It can give us some idea and instinctive capabilities of the capabilities of an LLM, but LLMs are inherently probabilistic and thus one-off examples cannot be used to exhaustively test capbabilities of LLMs. \n",
    "\n",
    "In order to exhaustively test LLM capabilities in different domains, the community has come up with [LLM evaluation benchmarks](https://www.evidentlyai.com/llm-guide/llm-benchmarks) which provide a more thorough testbed for evaluating LLM capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9c205a-44f7-45c9-b3d2-7e852e5f8a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f3465-1d6b-4d5c-a550-01302a528260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
